{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Multi-class Classification: Sign Language"
      ],
      "metadata": {
        "id": "9grKuoNdKnzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download and Prepare the Dataset"
      ],
      "metadata": {
        "id": "TM7t7g2KKsTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the training and test sets (the test set will actually be used as a validation set):"
      ],
      "metadata": {
        "id": "_2d5Jz6xLOzq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Pf0fvnFKklK"
      },
      "outputs": [],
      "source": [
        "# sign_mnist_train.csv\n",
        "!gdown --id 1z0DkA9BytlLxO1C0BAWzknLyQmZAp0HR\n",
        "# sign_mnist_test.csv\n",
        "!gdown --id 1z1BIj4qmri59GWBG4ivMNFtpZ4AXIbzg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_FILE = './sign_mnist_train.csv'\n",
        "VALIDATION_FILE = './sign_mnist_test.csv'"
      ],
      "metadata": {
        "id": "j67K78TKLSgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at how the data looks like within the csv file:"
      ],
      "metadata": {
        "id": "0QPzXMM_LWG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(TRAINING_FILE) as training_file:\n",
        "  line = training_file.readline()\n",
        "  print(f\"First line (header) looks like this:\\n{line}\")\n",
        "  line = training_file.readline()\n",
        "  print(f\"Each subsequent line (data points) look like this:\\n{line}\")"
      ],
      "metadata": {
        "id": "fmNw2R-yKxRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each file includes a header, and 785 pixel values\n",
        "- first row are names of columns\n",
        "- following rows are all values"
      ],
      "metadata": {
        "id": "toM1iqkrLaV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We assign the directory names into variables, and we can look at the filenames."
      ],
      "metadata": {
        "id": "0jOEXw5PKyge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pasring the dataset\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "s9goRj8GLC-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# GRADED FUNCTION: parse_data_from_input\n",
        "def parse_data_from_input(filename):\n",
        "  \"\"\"\n",
        "  Parses the images and labels from a CSV file\n",
        "\n",
        "  Args:\n",
        "    filename (string): path to the CSV file\n",
        "\n",
        "  Returns:\n",
        "    images, labels: tuple of numpy arrays containing the images and labels\n",
        "  \"\"\"\n",
        "  with open(filename) as file:\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Use csv.reader, passing in the appropriate delimiter\n",
        "    # Remember that csv.reader can be iterated and returns one line in each iteration\n",
        "    csv_reader = csv.reader(file, delimiter=',')\n",
        "    next(csv_reader)\n",
        "    temp_labels = []\n",
        "    temp_images = []\n",
        "\n",
        "    for row in csv_reader:\n",
        "      temp_labels.append(row[0]) #getting the 0th index of the row (the label), which is the first element\n",
        "      temp_images.append(row[1:]) #getting the rest of the elements in the row\n",
        "\n",
        "    temp_labels = np.array(temp_labels) #We don't reshape this because it's just 1 value\n",
        "    temp_images = np.reshape(np.array(temp_images), (-1, 28, 28))\n",
        "    #From (27455 x 785), we want (27455 x (28 x 28)). So we ignore the first parameter using -1, and set the remaining ones to 28 x 28.\n",
        "    #Imagine a 3D layer where we have 27455 sheets of 28x28 pictures.\n",
        "\n",
        "    labels = temp_labels.astype('float')\n",
        "    images = temp_images.astype('float')\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "cczcYRLULsPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the function\n",
        "training_images, training_labels = parse_data_from_input(TRAINING_FILE)\n",
        "validation_images, validation_labels = parse_data_from_input(VALIDATION_FILE)\n",
        "\n",
        "print(f\"Training images has shape: {training_images.shape} and dtype: {training_images.dtype}\")\n",
        "print(f\"Training labels has shape: {training_labels.shape} and dtype: {training_labels.dtype}\")\n",
        "print(f\"Validation images has shape: {validation_images.shape} and dtype: {validation_images.dtype}\")\n",
        "print(f\"Validation labels has shape: {validation_labels.shape} and dtype: {validation_labels.dtype}\")"
      ],
      "metadata": {
        "id": "F4xLennGLxyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "Training images has shape: (27455, 28, 28) and dtype: float64\n",
        "Training labels has shape: (27455,) and dtype: float64\n",
        "Validation images has shape: (7172, 28, 28) and dtype: float64\n",
        "Validation labels has shape: (7172,) and dtype: float64\n",
        "```"
      ],
      "metadata": {
        "id": "t4diQmEtL1rw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualizing numpy arrays"
      ],
      "metadata": {
        "id": "t6uAjRCBL42E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a sample of 10 images from the training set\n",
        "def plot_categories(training_images, training_labels):\n",
        "  fig, axes = plt.subplots(1, 10, figsize=(16, 15))\n",
        "  axes = axes.flatten()\n",
        "  letters = list(string.ascii_lowercase)\n",
        "\n",
        "  for k in range(10):\n",
        "    img = training_images[k]\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "    img = array_to_img(img)\n",
        "    ax = axes[k]\n",
        "    ax.imshow(img, cmap=\"Greys_r\")\n",
        "    ax.set_title(f\"{letters[int(training_labels[k])]}\")\n",
        "    ax.set_axis_off()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "plot_categories(training_images, training_labels)"
      ],
      "metadata": {
        "id": "R1OA04J6L9xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating generators for CNN"
      ],
      "metadata": {
        "id": "jOr6jJKkMBC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_generators(training_images, training_labels, validation_images, validation_labels):\n",
        "  \"\"\"\n",
        "  Creates the training and validation data generators\n",
        "\n",
        "  Args:\n",
        "    training_images (array): parsed images from the train CSV file\n",
        "    training_labels (array): parsed labels from the train CSV file\n",
        "    validation_images (array): parsed images from the test CSV file\n",
        "    validation_labels (array): parsed labels from the test CSV file\n",
        "\n",
        "  Returns:\n",
        "    train_generator, validation_generator - tuple containing the generators\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # In this section you will have to add another dimension to the data\n",
        "  # So, for example, if your array is (10000, 28, 28)\n",
        "  # You will need to make it (10000, 28, 28, 1)\n",
        "  # Hint: np.expand_dims\n",
        "  training_images = np.expand_dims(training_images, axis=3)\n",
        "  validation_images = np.expand_dims(validation_images, axis=3)\n",
        "\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class\n",
        "  # Don't forget to normalize pixel values\n",
        "  # and set arguments to augment the images (if desired)\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      rotation_range=10,\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      shear_range=0.1,\n",
        "      zoom_range=0.1,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        "  )\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow method\n",
        "  train_generator = train_datagen.flow(\n",
        "      x=training_images,\n",
        "      y=training_labels,\n",
        "      batch_size=32)\n",
        "\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  # Remember that validation data should not be augmented\n",
        "  validation_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255\n",
        "  )\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow method\n",
        "  validation_generator = validation_datagen.flow(\n",
        "      x=validation_images,\n",
        "      y=validation_labels,\n",
        "      batch_size=32)\n",
        "\n",
        "  ### END CODE HERE\n",
        "\n",
        "  return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "B_GtW8cYMCbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your generators\n",
        "train_generator, validation_generator = train_val_generators(training_images, training_labels, validation_images, validation_labels)\n",
        "\n",
        "print(f\"Images of training generator have shape: {train_generator.x.shape}\")\n",
        "print(f\"Labels of training generator have shape: {train_generator.y.shape}\")\n",
        "print(f\"Images of validation generator have shape: {validation_generator.x.shape}\")\n",
        "print(f\"Labels of validation generator have shape: {validation_generator.y.shape}\")"
      ],
      "metadata": {
        "id": "T0yCbo3PMIDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "Images of training generator have shape: (27455, 28, 28, 1)\n",
        "Labels of training generator have shape: (27455,)\n",
        "Images of validation generator have shape: (7172, 28, 28, 1)\n",
        "Labels of validation generator have shape: (7172,)\n",
        "```"
      ],
      "metadata": {
        "id": "AqIfJCBeMLFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Coding the CNN"
      ],
      "metadata": {
        "id": "qokVkgGCMM9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "def create_model():\n",
        "\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Define the model\n",
        "  # Use no more than 2 Conv2D and 2 MaxPooling2D\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', input_shape = (28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "      tf.keras.layers.Dense(26, activation = 'softmax')\n",
        "  ])\n",
        "\n",
        "\n",
        "  model.compile(optimizer = 'rmsprop',\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  ### END CODE HERE\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "-etN_DCeMMMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your model\n",
        "model = create_model()\n",
        "\n",
        "# Train your model\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "LTr8kJYJMR-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking a look at training history:"
      ],
      "metadata": {
        "id": "1G6K2AIHMTlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FanGnmWkMWBg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}