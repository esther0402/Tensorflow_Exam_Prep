{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUL54aONrS8x"
   },
   "source": [
    "#Handling Complex Images - Horses or Humans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcIi_f4JshuH"
   },
   "source": [
    "In this lab, you will continue using the ImageDataGenerator class to prepare the Horses or Humans dataset. This time, you will add a validation set so you can also measure how well the model performs on data it hasn't seen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hgW4Huw8rPDm"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0Yid8zUsi8w"
   },
   "outputs": [],
   "source": [
    "# Download the training set\n",
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n",
    "\n",
    "# Download the validation set\n",
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yNQhkyrPskz_"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "#unzip training set\n",
    "local_zip = './horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./horse-or-human')\n",
    "\n",
    "#unzip validation set\n",
    "local_zip = './validation-horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./validation-horse-or-human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RFsVcuMuv7pv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#training\n",
    "train_horse_dir = os.path.join('./horse-or-human/horses')\n",
    "train_human_dir = os.path.join('./horse-or-human/humans')\n",
    "\n",
    "#validation\n",
    "validation_horse_dir = os.path.join('./validation-horse-or-human/horses')\n",
    "validation_human_dir = os.path.join('./validation-horse-or-human/humans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHBJ-LUCxaW3",
    "outputId": "c19245b4-a42f-42d5-8d50-24da26dc3fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    './horse-or-human/',\n",
    "    target_size=(300,300),\n",
    "    batch_size=128,\n",
    "    class_mode='binary'\n",
    ")\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    './validation-horse-or-human',\n",
    "    target_size=(300,300),\n",
    "    batch_size=32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qQZC2TS1tDnH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    #input is 300x300 with 3 bytes color\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (300,300,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = RMSprop(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AA4nHTl9xWh5",
    "outputId": "7f4a89fc-e67f-438d-b8bd-e73b752b1f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8/8 [==============================] - 82s 10s/step - loss: 1.1168 - accuracy: 0.5028 - val_loss: 0.6558 - val_accuracy: 0.5000\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 84s 10s/step - loss: 0.6576 - accuracy: 0.5940 - val_loss: 0.5932 - val_accuracy: 0.7188\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 86s 11s/step - loss: 0.4854 - accuracy: 0.8231 - val_loss: 0.4755 - val_accuracy: 0.7695\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 93s 12s/step - loss: 0.3830 - accuracy: 0.8420 - val_loss: 0.7949 - val_accuracy: 0.7617\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 84s 10s/step - loss: 0.1759 - accuracy: 0.9366 - val_loss: 0.9730 - val_accuracy: 0.7734\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 84s 10s/step - loss: 0.1935 - accuracy: 0.9244 - val_loss: 1.1364 - val_accuracy: 0.7656\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 83s 10s/step - loss: 0.1311 - accuracy: 0.9522 - val_loss: 0.7798 - val_accuracy: 0.8594\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 86s 10s/step - loss: 0.1882 - accuracy: 0.9299 - val_loss: 0.4726 - val_accuracy: 0.8750\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 93s 12s/step - loss: 0.0789 - accuracy: 0.9833 - val_loss: 0.9124 - val_accuracy: 0.8516\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 86s 11s/step - loss: 0.0701 - accuracy: 0.9744 - val_loss: 1.3884 - val_accuracy: 0.8086\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 83s 10s/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 1.3235 - val_accuracy: 0.8359\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 89s 11s/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 1.4099 - val_accuracy: 0.8203\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 96s 12s/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.8160 - val_accuracy: 0.8789\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 88s 11s/step - loss: 1.9049 - accuracy: 0.8009 - val_loss: 1.5437 - val_accuracy: 0.6758\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 86s 11s/step - loss: 0.0682 - accuracy: 0.9889 - val_loss: 2.0682 - val_accuracy: 0.6953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0becfefca0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=8,\n",
    "    epochs=15,\n",
    "    verbose=1,\n",
    "    validation_data = val_gen,\n",
    "    validation_steps=8)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
