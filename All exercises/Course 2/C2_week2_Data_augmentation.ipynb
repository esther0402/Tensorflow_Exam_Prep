{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEPOqcza37Ey"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip"
      ],
      "metadata": {
        "id": "NyI0JRlB3_dT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "123e5357-b265-47c2-fa1c-7a2d6068f2cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-31 05:09:21--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 172.253.119.128, 108.177.121.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘cats_and_dogs_filtered.zip’\n",
            "\n",
            "cats_and_dogs_filte 100%[===================>]  65.43M   138MB/s    in 0.5s    \n",
            "\n",
            "2023-08-31 05:09:21 (138 MB/s) - ‘cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip the archive\n",
        "local_zip = './cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "5XCImheI4AXr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = 'cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "#train\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "#validation\n",
        "val_cats_dir = os.path.join(val_dir, 'cats')\n",
        "val_dogs_dir = os.path.join(val_dir, 'dogs')"
      ],
      "metadata": {
        "id": "3-NpE-uE4BaO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where we make the changes (We add data augmentation):"
      ],
      "metadata": {
        "id": "5G9xzl2V4IVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1/255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "val_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=20,\n",
        "    class_mode='binary',\n",
        "    target_size=(150,150)\n",
        ")\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    batch_size=20,\n",
        "    class_mode='binary',\n",
        "    target_size=(150,150)\n",
        ")"
      ],
      "metadata": {
        "id": "xupsXPs84Cgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a63b23-176b-4793-c703-16ee5946988a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model.compile(\n",
        "    optimizer=RMSprop(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "2-eYQ4L25aZq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=15,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "_e91iBA__8C1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}