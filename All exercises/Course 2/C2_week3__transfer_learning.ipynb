{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VniRp8rs5gLz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import img_to_array, load_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Horse or Human training dataset\n",
        "!wget -q -P /content/ https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human validation dataset\n",
        "!wget -q -P /content/ https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip"
      ],
      "metadata": {
        "id": "_TyTRe2b5uXM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip training set\n",
        "train_local_zip = './horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(train_local_zip, 'r')\n",
        "zip_ref.extractall('./horse-or-human')\n",
        "\n",
        "#unzip validation set\n",
        "val_local_zip = './validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(val_local_zip, 'r')\n",
        "zip_ref.extractall('./validation-horse-or-human')"
      ],
      "metadata": {
        "id": "QIGDv9N15vfK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#training\n",
        "train_horse_dir = os.path.join('./horse-or-human/horses')\n",
        "train_human_dir = os.path.join('./horse-or-human/humans')\n",
        "\n",
        "#validation\n",
        "validation_horse_dir = os.path.join('./validation-horse-or-human/horses')\n",
        "validation_human_dir = os.path.join('./validation-horse-or-human/humans')"
      ],
      "metadata": {
        "id": "syTz0u-H9fnv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "val_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    './horse-or-human/',\n",
        "    target_size=(300,300),\n",
        "    batch_size=128,\n",
        "    class_mode='binary'\n",
        ")\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    './validation-horse-or-human',\n",
        "    target_size=(300,300),\n",
        "    batch_size=32,\n",
        "    class_mode = 'binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvG-ObEh92KW",
        "outputId": "bd78e154-f126-4e9a-d628-3fa61a4e9261"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the additional changes: We add the transfer model."
      ],
      "metadata": {
        "id": "3_K4pGA194BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#download the pretrained model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shj69mcp96aJ",
        "outputId": "29b9a465-b9f0-4ae7-cc67-c6c9b2496d9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-31 05:11:13--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.128.128, 74.125.143.128, 173.194.69.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.128.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  26.3MB/s    in 3.4s    \n",
            "\n",
            "2023-08-31 05:11:17 (24.8 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ],
      "metadata": {
        "id": "tEvMzaL0-EBZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = InceptionV3(\n",
        "    input_shape=(150,150,3),\n",
        "    include_top=False,\n",
        "    weights=None\n",
        ")\n",
        "#we use our saved weights\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "#make all layers in pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable=False"
      ],
      "metadata": {
        "id": "Ya5k230X-N7M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we 'glue' it to our own model. We get the last output of the pre-trained model, which will be the input for our own model."
      ],
      "metadata": {
        "id": "AjYikfJh-sSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_desired_layer = pre_trained_model.get_layer('mixed7')\n",
        "last_output=last_desired_layer.output"
      ],
      "metadata": {
        "id": "0RGR6rSy-pLm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "def create_final_model(pre_trained_model, last_output):\n",
        "\n",
        "  x = layers.Flatten()(last_output)\n",
        "  x = layers.Dense(1024, activation = 'relu')(x)\n",
        "  x = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "\n",
        "  model = Model(pre_trained_model.input, x)\n",
        "\n",
        "  model.compile(\n",
        "      loss = 'binary_crossentropy',\n",
        "      optimizer = RMSprop(learning_rate=0.001),\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "msOUOWnW93pS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_final_model(pre_trained_model, last_output)"
      ],
      "metadata": {
        "id": "fJf_611m_qCd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=8,\n",
        "    epochs=15,\n",
        "    verbose=1,\n",
        "    validation_data = val_gen,\n",
        "    validation_steps=8)"
      ],
      "metadata": {
        "id": "RJUNFQVM99zg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}