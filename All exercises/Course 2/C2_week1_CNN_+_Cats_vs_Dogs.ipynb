{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXoXkej_03WM"
   },
   "source": [
    "#Using more sophisticated images with Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCSDZI8a01q6"
   },
   "source": [
    "In this lesson, you'll take that to the next level: building a model to classify real images of cats and dogs. Like the horses and humans dataset, real-world images also come in different shapes, aspect ratios, etc. and you will need to take this into account when preparing your data.\n",
    "\n",
    "In this lab, you will first review how to build CNNs, prepare your data with ImageDataGenerator and examine your results. You'll follow these steps:\n",
    "\n",
    "    Explore the example data of Dogs vs. Cats\n",
    "    Build and train a neural network to classify between the two pets\n",
    "    Evaluate the training and validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j8bFhrY-0-b-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Tz1e8yd0YJD",
    "outputId": "43086a92-c054-4ec7-b336-8a5c411ed53e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-31 04:46:57--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.145.128, 74.125.128.128, 74.125.143.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.145.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 68606236 (65M) [application/zip]\n",
      "Saving to: ‘cats_and_dogs_filtered.zip’\n",
      "\n",
      "cats_and_dogs_filte 100%[===================>]  65.43M  29.5MB/s    in 2.2s    \n",
      "\n",
      "2023-08-31 04:47:00 (29.5 MB/s) - ‘cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DCpBdwEx1Dfw"
   },
   "outputs": [],
   "source": [
    "#unzip the archive\n",
    "local_zip = './cats_and_dogs_filtered.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "F7L1lZmv1Q1a"
   },
   "outputs": [],
   "source": [
    "base_dir = 'cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "#train\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "#validation\n",
    "val_cats_dir = os.path.join(val_dir, 'cats')\n",
    "val_dogs_dir = os.path.join(val_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14gTbQuz2g55",
    "outputId": "83f764e4-7924-45c6-af4f-10ab3fd82f8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150)\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EeAK-s-611GW"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68GdWoeN8bOF"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=15,\n",
    "    verbose=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
