{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "D_ZSPRMcP2Yh",
        "5CT1XlQ2P4X9",
        "Bbxn7am1P5_b"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "D_ZSPRMcP2Yh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjVLuIkSb04-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utilities"
      ],
      "metadata": {
        "id": "5CT1XlQ2P4X9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "    \"\"\"\n",
        "    Visualizes time series data\n",
        "\n",
        "    Args:\n",
        "      time (array of int) - contains the time steps\n",
        "      series (array of int) - contains the measurements for each time step\n",
        "      format - line style when plotting the graph\n",
        "      start - first time step to plot\n",
        "      end - last time step to plot\n",
        "    \"\"\"\n",
        "\n",
        "    # Setup dimensions of the graph figure\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    if type(series) is tuple:\n",
        "\n",
        "      for series_num in series:\n",
        "        # Plot the time series data\n",
        "        plt.plot(time[start:end], series_num[start:end], format)\n",
        "\n",
        "    else:\n",
        "      # Plot the time series data\n",
        "      plt.plot(time[start:end], series[start:end], format)\n",
        "\n",
        "    # Label the x-axis\n",
        "    plt.xlabel(\"Time\")\n",
        "\n",
        "    # Label the y-axis\n",
        "    plt.ylabel(\"Value\")\n",
        "\n",
        "    # Overlay a grid on the graph\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Draw the graph on screen\n",
        "    plt.show()\n",
        "\n",
        "def trend(time, slope=0):\n",
        "    \"\"\"\n",
        "    Generates synthetic data that follows a straight line given a slope value.\n",
        "\n",
        "    Args:\n",
        "      time (array of int) - contains the time steps\n",
        "      slope (float) - determines the direction and steepness of the line\n",
        "\n",
        "    Returns:\n",
        "      series (array of float) - measurements that follow a straight line\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute the linear series given the slope\n",
        "    series = slope * time\n",
        "\n",
        "    return series\n",
        "\n",
        "def seasonal_pattern(season_time):\n",
        "    \"\"\"\n",
        "    Just an arbitrary pattern, you can change it if you wish\n",
        "\n",
        "    Args:\n",
        "      season_time (array of float) - contains the measurements per time step\n",
        "\n",
        "    Returns:\n",
        "      data_pattern (array of float) -  contains revised measurement values according\n",
        "                                  to the defined pattern\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate the values using an arbitrary pattern\n",
        "    data_pattern = np.where(season_time < 0.4,\n",
        "                    np.cos(season_time * 2 * np.pi),\n",
        "                    1 / np.exp(3 * season_time))\n",
        "\n",
        "    return data_pattern\n",
        "\n",
        "def seasonality(time, period, amplitude=1, phase=0):\n",
        "    \"\"\"\n",
        "    Repeats the same pattern at each period\n",
        "\n",
        "    Args:\n",
        "      time (array of int) - contains the time steps\n",
        "      period (int) - number of time steps before the pattern repeats\n",
        "      amplitude (int) - peak measured value in a period\n",
        "      phase (int) - number of time steps to shift the measured values\n",
        "\n",
        "    Returns:\n",
        "      data_pattern (array of float) - seasonal data scaled by the defined amplitude\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the measured values per period\n",
        "    season_time = ((time + phase) % period) / period\n",
        "\n",
        "    # Generates the seasonal data scaled by the defined amplitude\n",
        "    data_pattern = amplitude * seasonal_pattern(season_time)\n",
        "\n",
        "    return data_pattern\n",
        "\n",
        "def noise(time, noise_level=1, seed=None):\n",
        "    \"\"\"Generates a normally distributed noisy signal\n",
        "\n",
        "    Args:\n",
        "      time (array of int) - contains the time steps\n",
        "      noise_level (float) - scaling factor for the generated signal\n",
        "      seed (int) - number generator seed for repeatability\n",
        "\n",
        "    Returns:\n",
        "      noise (array of float) - the noisy signal\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the random number generator\n",
        "    rnd = np.random.RandomState(seed)\n",
        "\n",
        "    # Generate a random number for each time step and scale by the noise level\n",
        "    noise = rnd.randn(len(time)) * noise_level\n",
        "\n",
        "    return noise"
      ],
      "metadata": {
        "id": "JQncVPUsP36J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate synthetic data"
      ],
      "metadata": {
        "id": "Bbxn7am1P5_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
        "baseline = 10\n",
        "amplitude = 40\n",
        "slope = 0.05\n",
        "noise_level = 5\n",
        "\n",
        "# Create the series\n",
        "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
        "\n",
        "# Update with noise\n",
        "series += noise(time, noise_level, seed=42)\n",
        "\n",
        "# Plot the results\n",
        "plot_series(time, series)"
      ],
      "metadata": {
        "id": "IAD4PedXQQr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split dataset"
      ],
      "metadata": {
        "id": "vns6u_fTP7VO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define split time\n",
        "split_time = 1000\n",
        "\n",
        "#train set\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "\n",
        "#validation set\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]"
      ],
      "metadata": {
        "id": "ZCwsDAqfQSuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare features and labels"
      ],
      "metadata": {
        "id": "3s0aeJbrP8-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters\n",
        "\n",
        "window_size = 20\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000"
      ],
      "metadata": {
        "id": "Ktdc-IyAQt7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset window function\n",
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series) #generate a TF dataset\n",
        "  dataset = dataset.window(window_size+1, shift=1, drop_remainder=True) #window the data\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1)) #flatten the windows\n",
        "  dataset = dataset.map(lambda window: (window[:-1], window[-1])) #tuples w/ features + labels\n",
        "  dataset = dataset.shuffle(shuffle_buffer) #shuffle the windows\n",
        "  dataset = dataset.batch(batch_size).prefetch(1) #create batches of windows\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "qF5yDWRiQx-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate dataset windows\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)"
      ],
      "metadata": {
        "id": "AJibzT29Rc9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build the Model"
      ],
      "metadata": {
        "id": "rrQ2RhWYP-lO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We make a model made of `SimpleRNN` layers (which just routs its output back to the input).\n",
        "- It expects 2-dimensional tensor input with the shape `[batch, timesteps, feature]`. ith that, you need to reshape your window from `(32, 20)` to `(32, 20, 1)` using Lambda layers.\n",
        "- SimpleRNN uses tahn by default (outputs -1 to 1), so we use a lambda layer to scale the output by 100."
      ],
      "metadata": {
        "id": "tEC-yN8yRnn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#build the model\n",
        "model_tune = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                           input_shape=[window_size]),\n",
        "    tf.keras.layers.SimpleRNN(40, return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(40),\n",
        "    tf.keras.layers.Dense(1),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])"
      ],
      "metadata": {
        "id": "-D3qlhC9SGrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tune the learning rate"
      ],
      "metadata": {
        "id": "AYZan5mgS3zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the learning rate scheduler\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch/20))\n",
        "\n",
        "#initialize optimizer\n",
        "optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
        "\n",
        "#set the training parameters\n",
        "model_tune.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer)\n",
        "\n",
        "#train the model\n",
        "history = model_tune.fit(dataset, epochs=100, callbacks=[lr_schedule])"
      ],
      "metadata": {
        "id": "pJzvzhgUS5bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can visualize the results to pick an optimal learning rate."
      ],
      "metadata": {
        "id": "5424D2lKTgQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the learning rate array\n",
        "lrs = 1e-8 * (10 ** (np.arange(100) / 20))\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Set the grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot the loss in log scale\n",
        "plt.semilogx(lrs, history.history[\"loss\"])\n",
        "\n",
        "# Increase the tickmarks size\n",
        "plt.tick_params('both', length=10, width=1, which='both')\n",
        "\n",
        "# Set the plot boundaries\n",
        "plt.axis([1e-8, 1e-3, 0, 50])"
      ],
      "metadata": {
        "id": "OnYmkU1dTUVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can change the boundaries of the graph so it will look closer."
      ],
      "metadata": {
        "id": "cKEGpB4WTmfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Set the grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot the loss in log scale\n",
        "plt.semilogx(lrs, history.history[\"loss\"])\n",
        "\n",
        "# Increase the tickmarks size\n",
        "plt.tick_params('both', length=10, width=1, which='both')\n",
        "\n",
        "# Set the plot boundaries\n",
        "plt.axis([1e-7, 1e-4, 0, 20])"
      ],
      "metadata": {
        "id": "4P_3DMLVToxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can choose an optimal learning rate based on the results."
      ],
      "metadata": {
        "id": "r6Lv88JNTrv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the model"
      ],
      "metadata": {
        "id": "IuGzDvDjTulW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[window_size]),\n",
        "  tf.keras.layers.SimpleRNN(40, return_sequences=True),\n",
        "  tf.keras.layers.SimpleRNN(40),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 1e-6\n",
        "\n",
        "# Set the optimizer\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
        "\n",
        "# Set the training parameters\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(dataset,epochs=100)"
      ],
      "metadata": {
        "id": "v8MvSVsITqaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Prediction"
      ],
      "metadata": {
        "id": "qSxgNY_BTyUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize a list\n",
        "forecast = []\n",
        "\n",
        "#reduce the original series\n",
        "forecast_series = series[split_time - window_size:]\n",
        "\n",
        "#use model to predict data points per window size\n",
        "for time in range(len(forecast_series) - window_size):\n",
        "  forecast.append(model.predict(forecast_series[time:time + window_size][np.newaxis]))\n",
        "\n",
        "#convert to numpy array\n",
        "results = np.array(forecast).squeeze()\n",
        "\n",
        "#plot results\n",
        "plot_series(time_valid, (x_valid, results))"
      ],
      "metadata": {
        "id": "gj0dJfWiTzh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- You can optimize this step by leveraging Tensorflow models' capability to process batches. Instead of running the for-loop above which **processes a single window at a time**, you can pass in an entire batch of windows and let the model process that in parallel.\n",
        "- It does not shuffle the windows. That's because we want the output to be in its proper sequence so we can compare it properly to the validation set."
      ],
      "metadata": {
        "id": "q-J8qoTWUiK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_forecast(model, series, window_size, batch_size):\n",
        "    \"\"\"Uses an input model to generate predictions on data windows\n",
        "\n",
        "    Args:\n",
        "      model (TF Keras Model) - model that accepts data windows\n",
        "      series (array of float) - contains the values of the time series\n",
        "      window_size (int) - the number of time steps to include in the window\n",
        "      batch_size (int) - the batch size\n",
        "\n",
        "    Returns:\n",
        "      forecast (numpy array) - array containing predictions\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a TF Dataset from the series values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "\n",
        "    # Window the data but only take those with the specified size\n",
        "    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
        "\n",
        "    # Flatten the windows by putting its elements in a single batch\n",
        "    dataset = dataset.flat_map(lambda w: w.batch(window_size))\n",
        "\n",
        "    # Create batches of windows\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "    # Get predictions on the entire dataset\n",
        "    forecast = model.predict(dataset)\n",
        "\n",
        "    return forecast"
      ],
      "metadata": {
        "id": "I-gw6KyvUqJ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}